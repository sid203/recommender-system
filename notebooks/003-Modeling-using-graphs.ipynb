{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1a3a6637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import networkx as nx \n",
    "from itertools import permutations\n",
    "from math import factorial\n",
    "from sklearn.model_selection import train_test_split\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "\n",
    "ROOT = os.getenv('ROOT_FOLDER')\n",
    "df = pd.read_csv(os.path.join(ROOT, \"app/resources/rating.csv\"), usecols=['userId', 'movieId', 'timestamp',\n",
    "                                                                          'rating'])\n",
    "df = df.assign(timestamp=pd.to_datetime(df.timestamp),\n",
    "              movieId=df.movieId.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65e83cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((138493,), (26744,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.userId.unique().shape, df.movieId.unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bb8964",
   "metadata": {},
   "source": [
    "###  Train test \n",
    "\n",
    "Steps \n",
    "\n",
    "1. Randomly sample 10% of users and movies\n",
    "2. Keep movies and users that have atleast 10 number of edges in the dataset (this helps to stratify between train and test set)\n",
    "3. Train, test splits with stratification on movieIds (to ensure that there are no new movies in the test set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c91bc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_filter(df, col, thresh):\n",
    "    m = df[col].value_counts()>thresh\n",
    "    return df[df[col].isin(m[m].index)]\n",
    "\n",
    "\n",
    "def get_subsample(df, col, size=0.10):\n",
    "    uniques = np.unique(df[col]) if col else np.unique(df.index)\n",
    "    subsample = np.random.choice(uniques, size=int(len(uniques)*size), replace=False)\n",
    "    return df[df[col].isin(subsample)] if col else df[df.index.isin(subsample)]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "106ff3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "\n",
    "df_sample = get_subsample(df, 'userId', 0.10)\n",
    "df_sample = get_subsample(df_sample, 'movieId', 0.10)\n",
    "df_sample = movie_filter(df_sample, 'movieId', 10)\n",
    "df_sample = movie_filter(df_sample, 'userId', 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "3bd6b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.to_pickle(os.path.join(ROOT, \"app/resources/subsample.p\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80f4bf26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((144207, 3), (4551,), (840,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.shape,df_sample.userId.unique().shape,df_sample.movieId.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2203b095",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_sample, \n",
    "                                 test_size=0.2, \n",
    "                                 stratify=df_sample[['movieId']], \n",
    "                              random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d54eeadf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((115365, 3), (28842, 3))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc5533a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4551,), (840,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.userId.unique().shape,train.movieId.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45f85c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4442,), (840,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.userId.unique().shape,test.movieId.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4790faa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(test.userId).difference(set(train.userId))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "284e98e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(test.movieId).difference(set(train.movieId))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962cf10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(zip(test.userId, test.movieId)).difference(set(zip(train.userId, train.movieId))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba2a51d",
   "metadata": {},
   "source": [
    "###  User item Bipartite graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b54adf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_item_bipartite(df):\n",
    "    \n",
    "    B = nx.Graph()\n",
    "    B.add_nodes_from(df.userId.unique(), bipartite=0)\n",
    "    B.add_nodes_from(df.movieId.unique(), bipartite=1)\n",
    "    # add edges only between nodes of opposite sets\n",
    "    B.add_edges_from(list(zip(df.userId, df.movieId)))\n",
    "    return B\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73045ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = user_item_bipartite(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "629ed99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nx.write_gpickle(user_item_bipartite(test), os.path.join(ROOT, \"app/resources/user_item_graph_test.p\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9478fede",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gpickle(B, os.path.join(ROOT, \"app/resources/user_item_graph.p\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b457962",
   "metadata": {},
   "source": [
    "### Item Item graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46eebf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nPr(n, r):\n",
    "    return int(factorial(n)/factorial(n-r))\n",
    "\n",
    "\n",
    "def get_edge_weight_bool(graph, item1, item2):\n",
    "    \n",
    "    g = nx.common_neighbors(graph, item1, item2)\n",
    "    \n",
    "    if_edge = False\n",
    "    try:\n",
    "        if_edge = True if next(g) else if_edge\n",
    "    except Exception as e:\n",
    "        print(f\"No edge found between the items {item1} & {item2}\")\n",
    "\n",
    "    return if_edge\n",
    "\n",
    "def get_edge_weight_float(graph, item1, item2):\n",
    "    \n",
    "    \"\"\"\n",
    "    item1 -> item 2 : P(item2|item1) = P(item2 and item1)/P(item1)\n",
    "    \"\"\"\n",
    "    probab_items = len(list(nx.common_neighbors(graph, item1, item2)))\n",
    "    return 0 if probab_items==0 else len(list(graph.neighbors(item1)))/probab_items\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bed5ac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_item_item_graph(permutations_generator, user_item_graph, edge_weight_fn):\n",
    "    \n",
    "    out_graph = nx.DiGraph()\n",
    "    for item1, item2 in permutations_generator:\n",
    "        wt = edge_weight_fn(user_item_graph, item1, item2)\n",
    "        \n",
    "        if wt:\n",
    "            out_graph.add_edge(item1, item2) if wt is True else out_graph.add_edge(item1, item2, weight=wt)\n",
    "            \n",
    "    return out_graph\n",
    "\n",
    "\n",
    "\n",
    "def preference_vector(user, user_item_graph):\n",
    "    \"we have no weights in user_item graphs because we assume model is ratings agnostic\"\n",
    "    \n",
    "    nitems = user_item_graph.degree(user)\n",
    "    \n",
    "    return {item:1/nitems for item in user_item_graph.neighbors(user)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce359efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "713180"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nPr(845, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd39d67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 13s, sys: 618 ms, total: 2min 14s\n",
      "Wall time: 2min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "ss = train.movieId.unique()\n",
    "pairs_generator = permutations(ss, r=2)\n",
    "I = build_item_item_graph(pairs_generator, B, get_edge_weight_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b37333cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gpickle(I, os.path.join(ROOT, \"app/resources/item_item_graph.p\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db3ff68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/68/4wgymlkn7rq16v1dk6yh01780000gn/T/ipykernel_70743/870106938.py:1: DeprecationWarning: info is deprecated and will be removed in version 3.0.\n",
      "\n",
      "  nx.info(I)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DiGraph with 840 nodes and 569114 edges'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.info(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "41e12954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 14s, sys: 3.87 s, total: 2min 18s\n",
      "Wall time: 2min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "scores_100 = get_page_rank_scores(test.userId.unique()[:100], I, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ba310c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_rank_scores(users, item_item_graph, user_item_graph):\n",
    "    \n",
    "    scores = {user:\n",
    "              {movie:score for movie,score in nx.pagerank(item_item_graph, \n",
    "                                      personalization=preference_vector(user, user_item_graph)).items()\n",
    "              if movie not in list(user_item_graph.neighbors(user))}\n",
    "              \n",
    "          for user in users}\n",
    "    return scores\n",
    "    \n",
    "    \n",
    "def helper(args):\n",
    "    return get_page_rank_scores(*args)\n",
    "\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "        \n",
    "\n",
    "def merge_dicts(dicts):\n",
    "    return reduce(lambda x,y: {**x, **y}, dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8b6c7134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1462edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp \n",
    "\n",
    "mp.set_start_method(\"fork\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "921821dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "executor=ProcessPoolExecutor(max_workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7ae35096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.6 s, sys: 10.2 s, total: 50.8 s\n",
      "Wall time: 1h 1min 48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkProcess-8:\n",
      "Process ForkProcess-9:\n",
      "Process ForkProcess-7:\n",
      "Process ForkProcess-10:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/siddhanttandon/.pyenv/versions/3.8.0/lib/python3.8/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "args = [(batch, I, B) for batch in chunks(test.userId.unique(), 100)]\n",
    "out = [result for result in executor.map(helper, args)]\n",
    "\n",
    "out_merged = merge_dicts(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5bb35aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(out_merged, os.path.join(ROOT, \"app/resources/test_results.p\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be789c64",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "8d1bf5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryMetrics:\n",
    "    \"\"\"\n",
    "    Base class that calculates the given metric for all the queries present in the dataframe. The class takes a \\\n",
    "    dataframe. Every row of the dataframe is a document which must have a query id, relevance score and a predicted \\\n",
    "    score. These three column names can be set in the constructor of the derived class. The output of the class is a \\\n",
    "    dictionary with keys as query ids and values as metric score.\n",
    "    \n",
    "    :param query_col: name of the column of the dataframe having query ids\n",
    "    :param preds_col: name of the column of the dataframe having predicted scores\n",
    "    :param relevance_col: name of the column of the dataframe having relevance scores\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, query_col, preds_col, relevance_col):\n",
    "        self.query_col = query_col\n",
    "        self.preds_col = preds_col\n",
    "        self.relevance_col = relevance_col\n",
    "\n",
    "    def __totuple__(self, x):\n",
    "        return list(zip(x[self.relevance_col], x[self.preds_col]))\n",
    "\n",
    "    @staticmethod\n",
    "    def _sortByscore(x):\n",
    "        return sorted(x, key=lambda k: k[1], reverse=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def _sortByrelevance(x):\n",
    "        return sorted(x, key=lambda k: k[0], reverse=True)\n",
    "        \n",
    "    def calculate_metrics(self, df):\n",
    "        query_dict = {query_id: self.__totuple__(df[df.index.isin(q_index)])\n",
    "                      for query_id, q_index in df.groupby([self.query_col]).groups.items()}\n",
    "        \n",
    "        metric_dict = {query_id: self.get_metric(xx) for query_id, xx in query_dict.items()}\n",
    "        return metric_dict\n",
    "    \n",
    "    \n",
    "class Ndcg(QueryMetrics):\n",
    "    \"\"\"\n",
    "    This class implements the Normalized Discounted Cumulative Gain metric. Ndcg is a metric widely used in information\n",
    "    retrieval domain to evaluate quality of search results of a search engine. Since we care more about top ranking \\\n",
    "    documents rather than the bottom ranking documents, this metric penalizes more if ranking results have mistakes \\\n",
    "    in the top order compared to mistakes in the bottom order. The range of this metric is between 0-1 and a higher \\\n",
    "    score is better.\n",
    "    \n",
    "    This class assumes top ranking documents should have a higher relevance score. If there are 5 documents in the best\n",
    "    ranking order 1,2,3,4,5 then the relevance scores should be 5,4,3,2,1.\n",
    "    \n",
    "    The relevance scores can be scaled using the label_gain parameter which is a dictionary. For example to scale the \\\n",
    "    relevances 5,4,3,2,1 by a factor of 10 we can set label_gain={1:10,2:20,3:30,4:40,5:50} meaning the 1st ranking \\\n",
    "    document which has a relevance of 5 is now weighted as 50 and the least ranking document is weighted as 10.\n",
    "    \n",
    "    For a single query_id the metric can be calculated by calling Ndcg.get_metric method. The input should be a list \\\n",
    "    of tuples where every tuple is made of (relevance, score) where relevance is the relevance of the document and \\\n",
    "    score is the score of the document assigned by the estimator. The output is a score in float of the given query id.\n",
    "    \n",
    "    For multiple query ids the metric can be calculated by calling Ndcg.calculate_metrics which is a method of it's \\\n",
    "    baseclass. The method takes a dataframe having query id, relevance and predicted score columns. These columns can \\\n",
    "    be set in the constructor of the class. The output is a dictionary with keys as query ids and values as metric \\\n",
    "    score.\n",
    "    \n",
    "    :param k: integer specifying topk documents to consider when calculating ndcg score. \n",
    "    :param label_gain: dictionary with keys as relevance and values as corresponding weight for relevance.\n",
    "    :param _log: function to calculate logarithm. Default is np.log2 which is log base 2.\n",
    "    :param query_col: name of the column of the dataframe having query ids\n",
    "    :param preds_col: name of the column of the dataframe having predicted scores\n",
    "    :param relevance_col: name of the column of the dataframe having relevance scores\n",
    "    \n",
    "    Usage:\n",
    "    \n",
    "    df = pd.DataFrame({'query_id':[ii for i in range(5) for ii in [i]*5],\n",
    "                   'preds':[ii for i in range(5) for ii in np.random.random_sample((5,))],\n",
    "                   'relevance':[ii for i in range(5) for ii in np.random.choice(range(1,6),size=5, replace=False)]})\n",
    "                   \n",
    "    out = Ndcg(k=5,  query_col='query_id', preds_col='preds', relevance_col='relevance').calculate_metrics(df)\n",
    "    \n",
    "    #out\n",
    "    {0: 0.9542080637541479,\n",
    "     1: 0.7392561108165644,\n",
    "     2: 0.7875305117652345,\n",
    "     3: 0.9073155929493236,\n",
    "     4: 0.8386893446302166}\n",
    "     \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k, label_gain=None, _log=np.log2, \n",
    "                 query_col='userId', preds_col='score', relevance_col='rating'):\n",
    "        \n",
    "        super(Ndcg, self).__init__(query_col=query_col, preds_col=preds_col, relevance_col=relevance_col)\n",
    "        self.k = k\n",
    "        self.label_gain = label_gain if label_gain is not None else {i: i for i in range(32)}\n",
    "        self._log = _log\n",
    "    \n",
    "    def __getWeight__(self, rel):\n",
    "        return self.label_gain.get(rel, rel)\n",
    "        \n",
    "    def dcg(self, relevance_with_scores):\n",
    "        \n",
    "        relevances = [self.__getWeight__(rel) for rel, score in self._sortByscore(relevance_with_scores)[:self.k]]\n",
    "        indexes = np.arange(1, len(relevances)+1)\n",
    "        return np.sum(relevances/self._log(indexes+1))\n",
    "    \n",
    "    def idcg(self, relevance_with_scores):\n",
    "        \n",
    "        relevances = [self.__getWeight__(rel) for rel, score in self._sortByrelevance(relevance_with_scores)[:self.k]]\n",
    "        indexes = np.arange(1, len(relevances)+1)\n",
    "        return np.sum(relevances/self._log(indexes+1))\n",
    "\n",
    "    def get_metric(self, relevance_with_scores):\n",
    "        return self.dcg(relevance_with_scores)/self.idcg(relevance_with_scores)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a2e43029",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg = Ndcg(k=10, query_col='userId', preds_col='score', relevance_col='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1cee88d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataframe(test_results):\n",
    "\n",
    "    xx = {k:pd.DataFrame.from_dict(v, orient='index', \n",
    "                              columns=['score'],).reset_index().rename(columns={'index':'movieId'})\n",
    "            for k,v in test_results.items()\n",
    "        }\n",
    "    return pd.concat(xx).rename_axis(['userId', None]).reset_index(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a4c2b5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_scores = to_dataframe(out_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4a126610",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test2.merge(user_scores, on=['movieId', 'userId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "15fba638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.91615\n",
       "dtype: float64"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(ndcg.calculate_metrics(x), orient='index').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748d747c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f98631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c824248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac57d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7314f49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70a310e2",
   "metadata": {},
   "source": [
    "### Todo: \n",
    "\n",
    "1. Make function for personalization_vector for a given user \n",
    "2. Train and test splits and restrict the sample space \n",
    "3. Check how can we scale the solution\n",
    "4. run the algorithm \n",
    "5. evaluate using ndcg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
