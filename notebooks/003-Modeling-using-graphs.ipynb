{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a3a6637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import networkx as nx \n",
    "from itertools import permutations\n",
    "from math import factorial\n",
    "from sklearn.model_selection import train_test_split\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "\n",
    "ROOT = os.getenv('ROOT_FOLDER')\n",
    "df = pd.read_csv(os.path.join(ROOT, \"app/resources/rating.csv\"), usecols=['userId', 'movieId', 'timestamp',\n",
    "                                                                          'rating'])\n",
    "df = df.assign(timestamp=pd.to_datetime(df.timestamp),\n",
    "              movieId=df.movieId.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65e83cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((138493,), (26744,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.userId.unique().shape, df.movieId.unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bb8964",
   "metadata": {},
   "source": [
    "###  Train test \n",
    "\n",
    "Steps \n",
    "\n",
    "1. Randomly sample 10% of users and movies\n",
    "2. Keep movies and users that have atleast 10 number of edges in the dataset (this helps to stratify between train and test set)\n",
    "3. Train, test splits with stratification on movieIds (to ensure that there are no new movies in the test set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c91bc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_filter(df, col, thresh):\n",
    "    m = df[col].value_counts()>thresh\n",
    "    return df[df[col].isin(m[m].index)]\n",
    "\n",
    "\n",
    "def get_subsample(df, col, size=0.10):\n",
    "    uniques = np.unique(df[col]) if col else np.unique(df.index)\n",
    "    subsample = np.random.choice(uniques, size=int(len(uniques)*size), replace=False)\n",
    "    return df[df[col].isin(subsample)] if col else df[df.index.isin(subsample)]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "106ff3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "\n",
    "df_sample = get_subsample(df, 'userId', 0.10)\n",
    "df_sample = get_subsample(df_sample, 'movieId', 0.10)\n",
    "df_sample = movie_filter(df_sample, 'movieId', 10)\n",
    "df_sample = movie_filter(df_sample, 'userId', 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "10defc5a",
   "metadata": {},
   "source": [
    "# write to disk\n",
    "df_sample.to_pickle(os.path.join(ROOT, \"app/resources/subsample.p\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80f4bf26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((144207, 3), (4551,), (840,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.shape,df_sample.userId.unique().shape,df_sample.movieId.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2203b095",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_sample, \n",
    "                                 test_size=0.2, \n",
    "                                 stratify=df_sample[['movieId']], \n",
    "                              random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d54eeadf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((115365, 3), (28842, 3))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc5533a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4551,), (840,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.userId.unique().shape,train.movieId.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45f85c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4442,), (840,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.userId.unique().shape,test.movieId.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4790faa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(test.userId).difference(set(train.userId))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "284e98e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(test.movieId).difference(set(train.movieId))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962cf10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(zip(test.userId, test.movieId)).difference(set(zip(train.userId, train.movieId))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba2a51d",
   "metadata": {},
   "source": [
    "###  User item Bipartite graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b54adf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_item_bipartite(df):\n",
    "    \n",
    "    B = nx.Graph()\n",
    "    B.add_nodes_from(df.userId.unique(), bipartite=0)\n",
    "    B.add_nodes_from(df.movieId.unique(), bipartite=1)\n",
    "    # add edges only between nodes of opposite sets\n",
    "    B.add_edges_from(list(zip(df.userId, df.movieId)))\n",
    "    return B\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73045ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = user_item_bipartite(train)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8d68df81",
   "metadata": {},
   "source": [
    "# write test user item graph \n",
    "nx.write_gpickle(user_item_bipartite(test), os.path.join(ROOT, \"app/resources/user_item_graph_test.p\"))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e55905dc",
   "metadata": {},
   "source": [
    "# write train user item graph\n",
    "nx.write_gpickle(B, os.path.join(ROOT, \"app/resources/user_item_graph.p\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b457962",
   "metadata": {},
   "source": [
    "### Item Item graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46eebf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nPr(n, r):\n",
    "    return int(factorial(n)/factorial(n-r))\n",
    "\n",
    "\n",
    "def get_edge_weight_bool(graph, item1, item2):\n",
    "    \n",
    "    g = nx.common_neighbors(graph, item1, item2)\n",
    "    \n",
    "    if_edge = False\n",
    "    try:\n",
    "        if_edge = True if next(g) else if_edge\n",
    "    except Exception as e:\n",
    "        print(f\"No edge found between the items {item1} & {item2}\")\n",
    "\n",
    "    return if_edge\n",
    "\n",
    "def get_edge_weight_float(graph, item1, item2):\n",
    "    \n",
    "    \"\"\"\n",
    "    item1 -> item 2 : P(item2|item1) = P(item2 and item1)/P(item1)\n",
    "    \"\"\"\n",
    "    probab_items = len(list(nx.common_neighbors(graph, item1, item2)))\n",
    "    return 0 if probab_items==0 else len(list(graph.neighbors(item1)))/probab_items\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bed5ac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_item_item_graph(permutations_generator, user_item_graph, edge_weight_fn):\n",
    "    \n",
    "    out_graph = nx.DiGraph()\n",
    "    for item1, item2 in permutations_generator:\n",
    "        wt = edge_weight_fn(user_item_graph, item1, item2)\n",
    "        \n",
    "        if wt:\n",
    "            out_graph.add_edge(item1, item2) if wt is True else out_graph.add_edge(item1, item2, weight=wt)\n",
    "            \n",
    "    return out_graph\n",
    "\n",
    "\n",
    "\n",
    "def preference_vector(user, user_item_graph):\n",
    "    \"we have no weights in user_item graphs because we assume model is ratings agnostic\"\n",
    "    \n",
    "    nitems = user_item_graph.degree(user)\n",
    "    \n",
    "    return {item:1/nitems for item in user_item_graph.neighbors(user)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd39d67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 13s, sys: 618 ms, total: 2min 14s\n",
      "Wall time: 2min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "ss = train.movieId.unique()\n",
    "pairs_generator = permutations(ss, r=2)\n",
    "I = build_item_item_graph(pairs_generator, B, get_edge_weight_float)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a431b9bf",
   "metadata": {},
   "source": [
    "# write graph\n",
    "nx.write_gpickle(I, os.path.join(ROOT, \"app/resources/item_item_graph.p\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db3ff68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/68/4wgymlkn7rq16v1dk6yh01780000gn/T/ipykernel_70743/870106938.py:1: DeprecationWarning: info is deprecated and will be removed in version 3.0.\n",
      "\n",
      "  nx.info(I)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DiGraph with 840 nodes and 569114 edges'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.info(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "41e12954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 14s, sys: 3.87 s, total: 2min 18s\n",
      "Wall time: 2min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "scores_100 = get_page_rank_scores(test.userId.unique()[:100], I, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ba310c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_rank_scores(users, item_item_graph, user_item_graph):\n",
    "    \n",
    "    scores = {user:\n",
    "              {movie:score for movie,score in nx.pagerank(item_item_graph, \n",
    "                                      personalization=preference_vector(user, user_item_graph)).items()\n",
    "              if movie not in list(user_item_graph.neighbors(user))}\n",
    "              \n",
    "          for user in users}\n",
    "    return scores\n",
    "    \n",
    "    \n",
    "def helper(args):\n",
    "    return get_page_rank_scores(*args)\n",
    "\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "        \n",
    "\n",
    "def merge_dicts(dicts):\n",
    "    return reduce(lambda x,y: {**x, **y}, dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c063ec",
   "metadata": {},
   "source": [
    "### Calculate pagerank for all users in the test set using multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1462edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp \n",
    "\n",
    "mp.set_start_method(\"fork\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "921821dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "executor=ProcessPoolExecutor(max_workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7ae35096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.6 s, sys: 10.2 s, total: 50.8 s\n",
      "Wall time: 1h 1min 48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkProcess-8:\n",
      "Process ForkProcess-9:\n",
      "Process ForkProcess-7:\n",
      "Process ForkProcess-10:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/siddhanttandon/.pyenv/versions/3.8.0/lib/python3.8/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "args = [(batch, I, B) for batch in chunks(test.userId.unique(), 100)]\n",
    "out = [result for result in executor.map(helper, args)]\n",
    "\n",
    "out_merged = merge_dicts(out)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dfce78d4",
   "metadata": {},
   "source": [
    "pd.to_pickle(out_merged, os.path.join(ROOT, \"app/resources/test_results.p\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be789c64",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d1bf5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.core.evaluation import Ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2e43029",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg = Ndcg(k=10, user_col='userId', preds_col='score', relevance_col='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cee88d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataframe(test_results):\n",
    "\n",
    "    xx = {k:pd.DataFrame.from_dict(v, orient='index', \n",
    "                              columns=['score'],).reset_index().rename(columns={'index':'movieId'})\n",
    "            for k,v in test_results.items()\n",
    "        }\n",
    "    return pd.concat(xx).rename_axis(['userId', None]).reset_index(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "604b9612",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out_merged = pd.read_pickle(os.path.join(ROOT, \"app/resources/test_results.p\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4c2b5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_scores = to_dataframe(out_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a126610",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = user_scores.merge(df, on=['userId', 'movieId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb37812a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9161496048116643"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean ndcg across all users\n",
    "pd.DataFrame.from_dict(ndcg.calculate_metrics(x), orient='index').mean()[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
